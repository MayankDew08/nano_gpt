# ğŸ­ NanoGPT: Shakespeare Text Generator

<div align="center">

[![Live Demo](https://img.shields.io/badge/Demo-Live-success?style=for-the-badge&logo=netlify)](https://inspiring-axolotl-af5e73.netlify.app/)
[![API](https://img.shields.io/badge/API-Live-blue?style=for-the-badge&logo=fastapi)](https://nano-gpt.onrender.com)
[![Python](https://img.shields.io/badge/Python-3.10-blue?style=for-the-badge&logo=python)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green?style=for-the-badge&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue?style=for-the-badge&logo=docker)](https://www.docker.com/)

**A production-ready GPT-based text generation system trained on Shakespeare's complete works**

[Live Demo](https://inspiring-axolotl-af5e73.netlify.app/) â€¢ [API Docs](https://nano-gpt.onrender.com/docs) â€¢ [Report Bug](https://github.com/YOUR_USERNAME/nano_gpt/issues)

</div>

---

## ğŸ“‹ Table of Contents

- [Demo](#-demo)
- [Overview](#-overview)
- [Architecture](#-architecture)
- [Features](#-features)
- [Live Deployment](#-live-deployment)
- [Local Development](#-local-development)
- [Docker Deployment](#-docker-deployment)
- [API Documentation](#-api-documentation)
- [Project Structure](#-project-structure)
- [Technical Details](#-technical-details)
- [Screenshots](#-screenshots)
- [Acknowledgments](#-acknowledgments)
- [License](#-license)

---

## ğŸ¬ Demo

### Live Application
**Frontend:** [https://inspiring-axolotl-af5e73.netlify.app/](https://inspiring-axolotl-af5e73.netlify.app/)  
**Backend API:** [https://nano-gpt.onrender.com](https://nano-gpt.onrender.com)  
**API Documentation:** [https://nano-gpt.onrender.com/docs](https://nano-gpt.onrender.com/docs)

### Demo Video
<!-- Add your demo video here -->
_Coming soon..._

---

## ğŸŒŸ Overview

NanoGPT is a **decoder-only transformer architecture** implementation for character-level text generation, trained on the complete works of William Shakespeare. This project demonstrates end-to-end deep learning workflow from training to production deployment.

### Key Highlights

- ğŸ§  **Decoder-Only Transformer** - GPT-style architecture with 6 layers and 6 attention heads
- ğŸ­ **Shakespeare Dataset** - Trained on 1MB of Shakespearean text
- ğŸ‹ **Dockerized** - Fully containerized backend for easy deployment
- â˜ï¸ **Cloud Deployed** - Backend on Render, Frontend on Netlify
- âš¡ **FastAPI Backend** - High-performance REST API with automatic documentation
- ğŸ¨ **Modern UI** - Beautiful, responsive frontend with real-time statistics
- ğŸ“Š **Production Ready** - Optimized inference, logging, and error handling

### Built Following

This implementation follows **Andrej Karpathy's** ["Let's build GPT: from scratch, in code, spelled out"](https://www.youtube.com/watch?v=kCc8FmEb1nY) video tutorial, extended with production deployment capabilities.

---

## ğŸ—ï¸ Architecture

### Model Architecture: Decoder-Only Transformer

```
Input Text (Character-Level)
         â†“
   Token Embedding (384-dim)
         +
   Positional Embedding (256 ctx)
         â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Transformer Block  â”‚ Ã— 6 layers
   â”‚  â”œâ”€ Multi-Head Attn â”‚   (6 heads each)
   â”‚  â”œâ”€ Layer Norm      â”‚
   â”‚  â”œâ”€ Feed Forward    â”‚
   â”‚  â””â”€ Layer Norm      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   Linear + Softmax (65 vocab)
         â†“
   Generated Character
```

**Architecture Specifications:**
- **Type:** Decoder-only GPT
- **Layers:** 6 transformer blocks
- **Attention Heads:** 6 per layer
- **Embedding Dimension:** 384
- **Context Window:** 256 tokens
- **Vocabulary Size:** 65 unique characters
- **Total Parameters:** ~10M
- **Dropout:** 0.2

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (Netlify)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  HTML/CSS/JavaScript (Static Hosting)            â”‚  â”‚
â”‚  â”‚  - Interactive UI                                 â”‚  â”‚
â”‚  â”‚  - Real-time generation statistics                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ HTTPS/REST API
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Backend API (Render + Docker)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FastAPI + Uvicorn                                â”‚  â”‚
â”‚  â”‚  â”œâ”€ /generate - Text generation endpoint         â”‚  â”‚
â”‚  â”‚  â”œâ”€ /docs - Swagger UI                           â”‚  â”‚
â”‚  â”‚  â””â”€ CORS enabled for cross-origin requests       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Model Service                                    â”‚  â”‚
â”‚  â”‚  â”œâ”€ Pre-loaded GPT model (model.pth)             â”‚  â”‚
â”‚  â”‚  â”œâ”€ Cached vocabulary (input.txt)                â”‚  â”‚
â”‚  â”‚  â””â”€ Encode/Decode functions                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Features

### Frontend
- ğŸ¨ **Beautiful UI** - Theatrical theme with smooth animations
- ğŸ“ **Flexible Input** - Optional prompts with customizable generation length
- ğŸ² **Smart Randomization** - Auto-select token count from predefined options
- âš¡ **Real-time Stats** - Display generation time, tokens, and character count
- ğŸ“‹ **One-Click Copy** - Copy generated text to clipboard
- ğŸ“± **Fully Responsive** - Works seamlessly on all devices
- ğŸŒ **CORS Enabled** - Connects to deployed backend API

### Backend
- ğŸš€ **High Performance** - Optimized inference with cached vocabulary
- ğŸ§  **Smart Loading** - Model and vocabulary loaded once at startup
- ğŸ“Š **Detailed Logging** - Request/response times and generation metrics
- ğŸ”§ **Configurable** - Environment-based configuration
- ğŸ“– **Auto Documentation** - Swagger UI at `/docs`
- ğŸ‹ **Docker Ready** - Containerized for consistent deployment
- â˜ï¸ **Cloud Deployed** - Running on Render with auto-scaling

---

## ğŸŒ Live Deployment

### Access the Application

| Component | URL | Description |
|-----------|-----|-------------|
| **Frontend** | [https://inspiring-axolotl-af5e73.netlify.app/](https://inspiring-axolotl-af5e73.netlify.app/) | Interactive web interface |
| **Backend API** | [https://nano-gpt.onrender.com](https://nano-gpt.onrender.com) | REST API endpoint |
| **API Docs** | [https://nano-gpt.onrender.com/docs](https://nano-gpt.onrender.com/docs) | Interactive API documentation |

### Deployment Stack

- **Frontend:** Netlify (Static Site Hosting)
- **Backend:** Render (Containerized Web Service)
- **Containerization:** Docker
- **Base Image:** `python:3.10.13-slim`

---

## ğŸ’» Local Development

### Prerequisites

- Python 3.10+
- Docker (optional, for containerized deployment)
- Git

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/YOUR_USERNAME/nano_gpt.git
cd nano_gpt
```

2. **Install backend dependencies**
```bash
cd Backend
pip install -r requirements.txt
```

3. **Start the backend**
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

4. **Open the frontend**
```bash
# In a new terminal
cd Frontend
python -m http.server 8080
```

5. **Access locally**
- Frontend: `http://localhost:8080`
- Backend API: `http://localhost:8000`
- API Docs: `http://localhost:8000/docs`

---

## ğŸ‹ Docker Deployment

### Build & Run with Docker

```bash
# Build the image
docker build --platform=linux/amd64 -f Backend/Dockerfile -t nano_gpt .

# Run the container
docker run -d -p 8000:8000 --name nano_gpt nano_gpt

# View logs
docker logs -f nano_gpt

# Stop the container
docker stop nano_gpt
```

### Docker Configuration

The Dockerfile is optimized for production:
- Multi-stage dependency installation for faster rebuilds
- Slim Python base image to reduce size
- Proper layer caching for efficient builds
- Health checks and logging enabled

**Build Context:** Repository root  
**Dockerfile Location:** `Backend/Dockerfile`  
**Exposed Port:** 8000

---

## ğŸ“š API Documentation

### Endpoints

#### `GET /`
**Health check and API information**

**Response:**
```json
{
  "message": "API for NanoGPT is up and running!",
  "status": "online",
  "endpoints": {
    "generate": "/generate",
    "docs": "/docs"
  }
}
```

#### `POST /generate`
**Generate Shakespearean text**

**Request Body:**
```json
{
  "text": "To be or not to be",  // Optional prompt
  "new_tokens": 500              // Optional (uses random if null)
}
```

**Response:**
```json
{
  "prompt": "To be or not to be",
  "generated_text": "To be or not to be...",
  "tokens_generated": 500,
  "total_length": 2847,
  "generation_time_seconds": 12.456,
  "total_response_time_seconds": 12.523
}
```

**Random Token Options:** If `new_tokens` is `null`, randomly selects from `[500, 750, 1000, 1500, 2000, 2500]`

---

## ğŸ“‚ Project Structure

```
nano_gpt/
â”œâ”€â”€ Backend/
â”‚   â”œâ”€â”€ Dockerfile              # Docker build configuration
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ model.py                # GPT model architecture
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ run_server.bat          # Windows startup script
â”‚   â”œâ”€â”€ .gitignore              # Git ignore patterns
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ prompt.py           # Pydantic request/response models
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ model_load.py       # Model loading and caching
â”œâ”€â”€ Frontend/
â”‚   â”œâ”€â”€ index.html              # Single-page application
â”‚   â””â”€â”€ README.md               # Frontend documentation
â”œâ”€â”€ Makemore/                   # Training experiments
â”‚   â””â”€â”€ *.ipynb                 # Jupyter notebooks
â”œâ”€â”€ model.pth                   # Trained model weights (10M params)
â”œâ”€â”€ input.txt                   # Shakespeare training corpus
â”œâ”€â”€ gpt.py                      # Original training script
â”œâ”€â”€ biagram.py                  # Bigram baseline model
â”œâ”€â”€ gpt_dev.ipynb              # Development notebook
â”œâ”€â”€ START.bat                   # Quick start launcher
â””â”€â”€ README.md                   # This file
```

---

## ğŸ”§ Technical Details

### Model Configuration

| Parameter | Value |
|-----------|-------|
| Architecture | Decoder-only Transformer (GPT) |
| Layers | 6 |
| Attention Heads | 6 |
| Embedding Dimension | 384 |
| Context Length | 256 tokens |
| Vocabulary Type | Character-level |
| Vocabulary Size | 65 unique characters |
| Dropout Rate | 0.2 |
| Total Parameters | ~10M |
| Training Data | Shakespeare corpus (1MB) |

### Backend Stack

- **Framework:** FastAPI 0.100+
- **Server:** Uvicorn (ASGI)
- **Deep Learning:** PyTorch 2.10+
- **Validation:** Pydantic
- **Containerization:** Docker
- **Deployment:** Render

### Performance Optimizations

- âœ… Vocabulary loaded once at module import (zero request overhead)
- âœ… Model weights loaded at startup (fast inference)
- âœ… Encode/decode functions cached globally
- âœ… Async request handling
- âœ… Efficient Docker layer caching
- âœ… Minimal base image (`python:3.10.13-slim`)

---

## ğŸ“¸ Screenshots

### Frontend Interface
<!-- Add screenshots here -->
_Coming soon..._

### API Documentation (Swagger UI)
<!-- Add screenshot of /docs -->
_Coming soon..._

### Docker Deployment
<!-- Add screenshot of Docker running -->
_Coming soon..._

---

## ğŸ™ Acknowledgments

### Inspiration & Learning

This project was built following **[Andrej Karpathy's](https://karpathy.ai/)** exceptional tutorial series:

- ğŸ“º **Video:** ["Let's build GPT: from scratch, in code, spelled out"](https://www.youtube.com/watch?v=kCc8FmEb1nY)
- ğŸ“ **Paper:** ["Attention Is All You Need"](https://arxiv.org/abs/1706.03762) (Vaswani et al., 2017)
- ğŸ“ **Course:** [Neural Networks: Zero to Hero](https://karpathy.ai/zero-to-hero.html)

### Key Concepts Learned

- Decoder-only transformer architecture
- Multi-head self-attention mechanism
- Positional embeddings
- Layer normalization and residual connections
- Character-level tokenization
- Autoregressive text generation
- Production deployment with Docker

### Technologies Used

- **PyTorch** - Deep learning framework
- **FastAPI** - Modern Python web framework
- **Docker** - Containerization platform
- **Render** - Cloud deployment platform
- **Netlify** - Static site hosting

---

## ğŸ“„ License

This project is open source and available for educational purposes.

---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome!

---

<div align="center">

**Built with ğŸ’œ by following Andrej Karpathy's teachings**

â­ Star this repo if you found it helpful!

</div>
